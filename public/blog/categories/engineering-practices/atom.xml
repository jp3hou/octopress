<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Engineering Practices | Julia Chou]]></title>
  <link href="http://jpchou.com/blog/categories/engineering-practices/atom.xml" rel="self"/>
  <link href="http://jpchou.com/"/>
  <updated>2018-06-28T15:57:33-07:00</updated>
  <id>http://jpchou.com/</id>
  <author>
    <name><![CDATA[Julia Chou]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Sidekiq-ifying Emails at Reflektive]]></title>
    <link href="http://jpchou.com/blog/2018/06/24/sidekiq-ifying-emails-at-reflektive/"/>
    <updated>2018-06-24T11:01:11-07:00</updated>
    <id>http://jpchou.com/blog/2018/06/24/sidekiq-ifying-emails-at-reflektive</id>
    <content type="html"><![CDATA[<p>At Reflektive, we offer the option of sending reminder emails after kicking off performance review cycles in order to notify participants of that cycle that they should fill out their reviews. We used <a href='https://github.com/collectiveidea/delayed_job' target='blank'>Delayed::Job</a>, an asynchronous priority queue system pioneered by the Shopify engineering team, to handle the delivery of those emails.</p>

<p>However, we noticed that there was a huge bottleneck when it came to delivering emails to cycles with large numbers of participants. For instance, one company that had approximately 30,000 employees would clog up our worker queues for hours, preventing other companies from sending out their own emails while this large job was still being processed.</p>

<p>One solution might have been to just throw more hardware at it, to spin up more DJ workers to hammer through the job queues. However, we decided to explore the option of using <a href='https://github.com/mperham/sidekiq' target='blank'>Sidekiq</a> as an alternative asynchronous job processing system.</p>

<p>Some of the factors leading to choosing Sidekiq included the fact that Sidekiq has higher concurrency than Delayed::Job because it leverages threads as opposed to single processes.</p>

<p>In addition, Delayed::Job stores its queued jobs in a database table (in our case, Postgres) while they&rsquo;re waiting for a DJ worker to process it. We opted to pair Sidekiq with Redis, an in-memory datastore. This results in a much lower I/O cost because the threads processing Sidekiq jobs don&rsquo;t have to make database queries every time they fetch a new job.</p>

<p>Below are some of Sidekiq&rsquo;s performance statistics (obtained from their Github page)</p>

<p><img class="center" src="/images/sidekiq_performance.png"></p>

<p><br/></p>

<h3>Converting a Delayed::Job to Sidekiq</h3>


<p>The process for converting a Delayed::Job worker to Sidekiq was fairly straightforward. The general structure of our DJ email worker code looked something like this:</p>

<pre><code>class DelayedJobEmail
  attr_reader :employee

  def initialize(employee)
    @employee = employee
  end

  def perform
    schedule_email(employee)
  end
end

# Enqueueing this email job:
job = DelayedJobEmail.new(Employee.find(123))
Delayed::Job.enqueue(job)
</code></pre>

<p>The equivalent Sidekiq implementation of that email worker would look like this:</p>

<pre><code>class SidekiqEmail
  include Sidekiq::Worker
  sidekiq_options queue: :process_email

  def perform(employee_id) # Note that Sidekiq does not accept Employee objects
    employee = Employee.find(employee_id)
    schedule_email(employee)
  end
end

# Enqueueing this email job:
SidekiqEmail.perform_async(123)
</code></pre>

<p>It&rsquo;s worth noting that Sidekiq will perform a JSON dump and load of arguments passed into its workers, so it only accepts pure JSON data types. This increases the consistency of data for edge cases where data has changed from underneath in the time that a job has spent enqueued and waiting for a worker to process it, but it will increase the total number of database calls made.</p>

<p><br/></p>

<h3>Testing Sidekiq Jobs</h3>


<p>Of course, for every piece of code, we have to write corresponding tests. Below are various methods of testing Sidekiq jobs in Minitest. They are all different ways of testing the same thing.</p>

<pre><code>require 'sidekiq/testing'

class SidekiqEmailTest
  def setup
    Sidekiq::Testing.fake! # Should be fake by default
  end

  def teardown
    Sidekiq::Worker.clear_all # Ensure jobs don't linger between tests
  end

  test '#perform delivers an email (Sidekiq fake mode)' do
    SidekiqEmail.perform_async(123)
    assert_equal(1, SidekiqEmail.jobs.size)
    SidekiqEmailWorker.drain
    # Assert that email was sent properly
  end

  test '#perform delivers an email (Sidekiq inline mode)' do
    Sidekiq::Testing.inline! do
      SidekiqEmail.perform_async(123)
      # Assert that email was sent properly
    end
  end

  test '#perform delivers an email (direct testing)' do
    SidekiqEmail.new.perform(123)
    # Assert that email was sent properly
  end
end
</code></pre>

<p><br/></p>

<h3>Configuring Sidekiq Workers</h3>


<p>Now that we have set up enqueueing Sidekiq jobs, it is a simple matter to spin up a process to start working on those jobs.
The Sidekiq rake command allows you to configure the concurrency, weight, and queues for each process as follows:</p>

<pre><code>bundle exec sidekiq -c 20 -q process_email,2 -q deliver_email,1
</code></pre>

<p>The <code>-c</code> flag controls the concurrency of the worker, in this case, 20. The <code>-q</code> commands specify which queues this worker will be pulling jobs from, and the <code>,2</code> and <code>,1</code> after the queue names indicate the weighted priority given to these queues. In this case, jobs from the <code>process_email</code> queue will be processed twice as frequently as those from the <code>deliver_email</code> queue.</p>

<p><br/></p>

<h3>Monitoring Queues</h3>


<p>We use NewRelic to monitor our application&rsquo;s performance, and we wanted to be able to leverage NewRelic to provide further transparency and statistics for our new Sidekiq queues as well. To this end, we set up a Heroku dyno to continually publish our Sidekiq queue sizes as custom events to our NewRelic instance. This way, we can see whether or not a queue is backed up, investigate the causes of any bottlenecks that we observe, and determine whether or not we should allocate more workers to process jobs.</p>

<p>The code we used to publish custom NewRelic events looked something like as follows:</p>

<pre><code>module QueueSizeMonitor
  def self.publish_queue_information
    Sidekiq::Queue.all.each do |queue|
      publish(queue.name, queue.size)
    end

    publish('scheduled', ::Sidekiq::ScheduledSet.new.size)
    publish('retries', ::Sidekiq::RetrySet.new.size)
    publish('dead', ::Sidekiq::DeadSet.new.size)
  end

  def self.publish(queue_name, queue_size)
    ::NewRelic::Agent.record_custom_event('QueueSizeMonitor', name: queue_name, size: queue_size)
  end
end
</code></pre>

<p>And afterwards, we were able to query those custom events in NewRelic and compile a chart to visualize how our Sidekiq queue sizes vary over time.</p>

<p><img class="center" src="/images/sidekiq_queue_size_newrelic.png" width="600"></p>

<p><br/></p>

<h3>Results and Next Steps</h3>


<p>After some monitoring, we discovered that switching from Delayed::Job to Sidekiq resulted in about a 4.5x improvement in throughput! We were able to complete a 30,000 employee email campaign in under an hour. We did hit some snags where we discovered that the concurrency we had set for our Sidekiq workers was a little too high and was resulting in a lot of open database connections at once, and we ended up scaling that down.</p>

<p>Moving forward, we are pushing to convert more Delayed::Job work over to Sidekiq.</p>
]]></content>
  </entry>
  
</feed>
